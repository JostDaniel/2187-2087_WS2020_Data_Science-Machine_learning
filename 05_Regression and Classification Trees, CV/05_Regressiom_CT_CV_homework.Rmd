---
title: "Regression and Classification Trees, Cross Validation - Homework"
author: "GROUP 4: Leonard Fidlin (h01352705), Daniel Jost (h01451889), Anne Valder (h11928415)"
output: 
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align = 'center')

```

# Classification Tree with the Voting

# Input data

Install and load the required packages.
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}

# Später schauen ob wir alle aus der VL brauchen ! 

library(rpart)
library(rpart.plot) 
library(precrec)
library(caret) ## funktioniert beir mir nicht
library(party)
library(libcoin) # noch dazu ?

library(tidyverse)
library(vcd)
library(RColorBrewer)
library(viridis)
library(knitr)
library(tinytex)
library(wooldridge)
library(glmnet) ## funktioniert beir mir nicht

# Set wd to Set the path to the data
data_path = "."

voting <- read_delim(file.path(data_path, "voting.csv"), ";", 
                      escape_double = FALSE, col_types = cols(age = col_number()), 
                      locale = locale(decimal_mark = ",", grouping_mark = "."), trim_ws = TRUE)

```

# Task 1) Estimate a classification tree using cross validation predicting the variable w1_q24

```{r }
# manuell und wenn ja welche model specification oder mit caret???
set.seed(123) ## warum??? 

## Seperate the voting data set into test and training data
voting <- 
  voting %>%
  mutate(train_index = sample(c("train", "test"), nrow(voting), replace=TRUE, prob=c(0.75, 0.25)))

voting_train <- voting %>% filter(train_index=="train")
voting_test <- voting %>% filter(train_index=="test")

tree <- rpart(w1_q24 ~ gender + age + bundesland, data = voting_train, cp=.01)
tree
summary(tree)

###### alternative mit caret #####

control <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
                        savePredictions = T, classProbs = T, summaryFunction = twoClassSummary)

```

#Task 2) Plot a tree graph of the model with the best performance. Explain how you come to your prediction in one of the terminal nodes

```{r}

rpart.plot(tree, box.palette="RdBu", nn=FALSE, type=2)

```

#Task 3) Make a confusion matrix of the model and interpret the results. 
# 3.1) Regarding which two categories do you find the highest and lowest sensitivity?
# 3.2) How well would you judge the predictive performance of the model?
# 3.3) What would be the "naive prediction" in such a multiclass prediction problem?

```{r}

voting_train$prediction_tree <- predict(tree, newdata = voting_train, type = c("class")) 
confusion <- confusionMatrix(voting_train$survived_label, voting_train$prediction_tree)
confusion

```

#Task 4) Estimate the model across a wide range of parameters of the model and plot the accuracy in the training and in the test data against the parameters. What can you see? what problem does this relate to?

```{r}

```

#Task 5) Simplify the model by only trying to predict if somebody voted for the ÖVP or not,
re-estimate the model (again by using CV) as well as estimating a logit model in the training
data utilizing whatever variables you find appropriate

```{r}

```

#Task 6) Compute the confusion matrix and ROC-curves for both models. Which one performs better and why? Where would you set the cut-off-point? 

```{r}

```




