---
title: "Equality of Opportunity Seminar Paper"
author: "Leonard Fidlin, Daniel Jost, Anne Valder"
date: "14 1 2021"
bibliography: bibliography.bib
output: 
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
subtitle: Data Science and Machine Learning 2187 & 2087
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
```

# **Introduction**
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
library(rpart)
library(rpart.plot) 
library(precrec)
library(caret)       
library(party)
library(tidyverse)
library(vcd)
library(RColorBrewer)
library(knitr)
library(glmnet)  
library(haven)
library(fst)
library(ranger)
library(tuneRanger)
library(xgboost)
```
# **Data Wrangling**
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
data_path ="."
getwd()
hhi2019 <- read_sav(file.path(data_path,"wetransfer-a0b059", "hhi2019en_1.0.sav"))
hse2019 <- read_sav(file.path(data_path,"wetransfer-a0b059", "hse2019en_1.0.sav"))
wrk2019 <- read_sav(file.path(data_path,"wetransfer-a0b059", "wrk2019en_1.2.sav"))
inc2019 <- read_sav(file.path(data_path,"wetransfer-a0b059", "inc2019en_1.0.sav"))

# hhi2019 %>% left_join(select(wrk2019 %>% select(c(nohhold,burgst, branche)), by = "nohhold"))

sub_wrk2019 <- wrk2019 %>% select(c(nohhold,burgst, branche))

sub_inc <- inc2019 %>% select(c(nohhold, ij161, in49a))


join <- hhi2019 %>% left_join(sub_wrk2019, by ="nohhold")
netherlands_survey_data <- join %>%  left_join(sub_inc, by = "nohhold")

summary(netherlands_survey_data) %>% head()

# We decide to drop
sum(is.na(netherlands_survey_data$in49a))

```
# **Research Question**
The selection of circumstances is a key aspect for an empirical analysis of inequality of opportunity, because estimates have been shown to be sensitive to the number of types considered [@brunori20].


# **Data**
@brunori20 choose the circumstances based on the data quality in their survey data. Opting for fewer missing entries in each catetgory than other characteristics. In their German focused paper they use: sex, migration background, resident in either East or West Germany (not important for our Dutch sample), Father's and Mother's education and training, Father's and Mother's occupation measured by the ISCO code, number of siblings, and an indicator of dissability. Their sample is further restricted to ages 30-60.
In their "original" EU-SILC data paper the use the following circumstances which we could find in the Dutch data: 

General Household Information:
Respondents sex (male, female) (GESLACHT), number of household members (AANTALHH), number of children in the household (AANTALKI), Highest level of education completed (OPLMET), primary occupation of the respondent (BEZIGHEI), type of accommodation (WONING).

Questionaire Household and Work:
Marital Status (BURGST), Father/Mother main occupation/job (BRANCHE), 

Total Gross Income Category (IJ161BR thru IJ16BR3), Total Net income of household (INKHH)
Inheritance? If yes then: Inheritance of 100,000 or 500,000 should make sense: (HER2), (HER3)

Questionaire on Accommodation and mortgages: tenancy status (WO1)

What we dont have is migration status, number of wokring adults in households, managerial position of father/mother

# **Method**: Conditional Inference Trees

* `ctree` from party package in R
* recursive partitioning just like `rpart`
* `rpart`: maximizing an information measure
* `ctree`: significance test procedure

### Advantages

**Advantages of Trees:** straightforward to interpret

**Advantages of Trees over linear regression models:** very large set of observations can be used & model speciÔ¨Åcation is no longer exogenously given

**Advantages of Conditional Inference Trees over Regression and Classification Trees (CART):** the algorithm automatically provides a test for the null hypothesis of equality of opportunity & prevents overfitting while CART "cannot distinguish between a significant and an insignificant improvement in the information measure" (Mingers 1987, as cited in @hot, 2) & consider the distributional properties of the measures.


### Procedure 

The algorithm follows a stepwise procedure [@brunori20, 7-8]:

1. **Choose confidence level**
2. **Choose feature:** test all the null hypotheses of independence between the individual outcome and each of all the observable circumstances
    i) no hypothesis can be rejected: stop
    ii) one or more circumstance is siginificant: select the circumstance with the smallest p-value and proceed
3. **Choose split:** for every possible way the selected circumstance can divide the sample into two subgroups, test the hypothesis of same mean outcome in the two resulting subgroups. Choose the splitting point with the smallest p-value
4. **Repeat :)**


# **Results**

# **Conclusion**

# **References**