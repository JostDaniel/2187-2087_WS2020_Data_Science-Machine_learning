---
title: "AT2019 Data Wrangling"
author: "Daniel Jost, Leo Fidlin, Anne Valder"
date: "1/31/2021"
output: 
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
subtitle: Data Science and Machine Learning 2187 & 2087
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
```

** To Do's **

Adapt Graphs and Summary Statistics

Combine all the data in one RMD file - Dont Confuse names

Apply forest to different countries

Compare Cross-Country Results - Variable Importance synthetic countries comparison, Gini comparison across countries

RMSE für Forest berechnen

Text schreiben


**Libraries**
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
library(tidyverse)
library(readr)          # import
library(rpart)          # regression trees
library(rpart.plot)     # regression tree plots
library(summarytools)   # summary statistics
library(party)          # ctree
library(partykit)       # ctree
library(caret)
library(forecast)
library(ineq) #Gini
library(precrec) # ROC curves
# library(mboost)
# library(vcd)
library(RColorBrewer)
# library(knitr)
# library(glmnet)  
# library(haven)
# library(fst)
# library(ranger)
# library(tuneRanger)
# library(xgboost)
```
**Data import**
TEXT
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
# setting the data path
data_path ="./AT2019"

# accessing the data
data19_p <- read.csv(file.path(data_path, "p_silc2019_ext.csv"), sep = ";")# personal data
# data19_pID <- read.csv(file.path(data_path, "id_schluessel_r_ext.csv"), sep = ";")  # personal ID
# data19_h <- read.csv(file.path(data_path, "h_silc2019_ext.csv"), sep = ";")  # household data
# data19_hID <- read.csv(file.path(data_path, "id_schluessel_d_ext.csv"), sep = ";")  # household ID
# data19_h <- data19_h %>% select(hy020, Hid) 
```
**Data Wrangling**
TEXT
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
# Renaming important variables for readability of tree

# data19_p <- data19_p %>%  left_join(data19_h, by = "Hid")

# A big problem is that the actualy annual income variable (hy010) is coded as a character variable and not as a numeric variable as it should be in the EU-Silc dataset and as we have it in our synthetic set.

# Problem the Austrian dataset does not contain information on the mother or the fathers country of birth, but merely their citizenship

data19 <- data19_p %>% 
  select(sex, P038004, P110000nu, P111010nu, alter, M009010, M010000, M014000, M016000, M017000, M020010, M021000, M025000, M027000, M028000, M004000, M001300, M001510, M003100, M001100, M001200, M002000, M001500) %>% 
  rename("inc_net" = P038004,               # gross monthly income
         "country_birth" = P110000nu,       # country of birth of respondent
         "citizenship" = P111010nu,         # citizenship of respondent
         "age" = alter,                     # age of respondent
         "father_cit" = M009010,            # citizenship of father at age 14
         "father_edu" = M010000,            # education of father at age 14 (höchster abschluss)
         "father_occup_stat" = M014000,     # occupational status of father at age 14
         "father_occup" = M016000,          # main occupation of father at age 14
         "father_manag" = M017000,          # managerial position of father at age 14            
         "mother_cit" = M020010,            # citizenship of mother at age 14
         "mother_edu" = M021000,            # education of mother at age 14
         "mother_occup_stat" = M025000,     # occupational status of mother at age 14
         "mother_occup" = M027000,          # main occupation of mother at age 14
         "mother_manag" = M028000,          # managerial position of mother at age 14
         "tenancy" = M004000,               # tenancy at age 14
         "children" = M001300,              # number of children (under 18) in respondent’s household at age 14
         "adults" = M001510,                # number of adults (aged 18 or more) in respondent’s household
         "adults_working" = M003100,        # number of working adults (aged 18 or more) in respondent’s household
         "father_present" = M001100,
         "mother_present" = M001200,
         ) %>%    
  filter(age %in% (27:59), inc_net > 0, mother_present > 0, father_present > 0, father_cit > 0, mother_cit > 0)  %>%      # We drop all answers where the respondents refused or were not able to provide information
  mutate("inc_net_log" = log(inc_net),  "both_parents_present" = father_present + mother_present, # 4 = none present, 3 = one present, 2 = both present
         sex = factor(ifelse(as.numeric(sex)==2, 1,0)), 
         country_birth = factor(country_birth, labels = c(1, 2, 2, 2, 3, 3)), # Austria, EU, Non-EU
         father_cit = ifelse(father_cit == 1, 1, 2),                          # Austria and Other
         mother_cit = ifelse(mother_cit == 1, 1, 2))                          # recode(country_birth, "1" = "Austria", "EU" = 2, "EU" = 3, "EU" = 4, "non-EU" = 5, "non-EU" = 6)) # logged net income per month of respondent
```

**Data Exploration and Visualization**
The ad-hoc module on intergenerational transmission of disadvantages only includes "selected respondents aged over 24 years and less than 60 years". This is why we exclude them: coding '-6' means that year of birth is outside of 1969 and 1994 range or the interviw was a proxy interview. Additionally, we exclude all respondents that where not part of this ad-hoc modul even if of the desired age.  

mother/father_edu: -3: not applicable (no mother/father, mother/father not present....)

```{r}
print(dfSummary(data19), method="render")
```

```{r}
ineq(data19$inc_net, type = "Gini")
plot(Lc(data19$inc_net), col = "darkred", lwd = 3)
```

Age pyramide
```{r}
# library("RColorBrewer")
# display.brewer.all()
data19 %>% 
ggplot(aes(x = age, fill=sex))  + 
  geom_bar(data = subset(data19, sex==1)) +
  geom_bar(data = subset(data19, sex==0), aes(y=..count..*(-1))) + 
  scale_x_continuous(breaks = seq(27,59,2), labels=abs(seq(27,59,2))) +
  scale_fill_manual(name = "Sex", labels = c("Male", "Female"), values=c("springgreen2", "slateblue1")) +
  labs(title = "Age pyramide of ad-hoc module on intergenerational transmission of disadvantages", x = "Age", y = "") +
  theme_bw() +
  coord_flip()

```


DANIEL ?! Correlation plot DANIEL?!
```{r}
library(corrplot)
library(Hmisc)

class(data19)

rcorr <- rcorr(as.matrix(data19))

corrplot(rcorr, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```

**Regression Tree**
```{r}
set.seed(123)

formula = inc_net_log ~ sex + country_birth + father_cit + father_edu + father_occup_stat + father_occup + father_manag + mother_cit + mother_edu + mother_occup_stat + mother_occup + mother_manag + tenancy + children + adults + adults_working + both_parents_present

data19 <- data19 %>%
  mutate(train_index = sample(c("train", "test"), nrow(data19), replace=TRUE, prob=c(0.80, 0.20)))

train <- data19 %>% filter(train_index=="train")
test <- data19 %>% filter(train_index=="test")

# tree_1 <- rpart(formula, data = train, cp=.003)
# tree_1

# rpart.plot(tree_1, box.palette="RdBu", nn=FALSE, type=2)

# test$prediction_tree <- predict(tree_1, newdata = test, type = c("matrix"))

# Here we could add the MSE or RMSE measure to compare performance
```

```{r}
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 10, savePredictions = T)

tuning_grid <- expand.grid(cp = seq(0, 0.02, by= 0.005))
tuning_grid

caret_rpart <- train(formula, data = data19, method = "rpart", trControl = fitControl, tuneGrid = tuning_grid, metric = "RMSE", na.action = na.pass)

caret_rpart
```

```{r}
tree_caret_final <- caret_rpart$finalModel
rpart.plot(tree_caret_final, box.palette="RdBu", nn=FALSE, type=2)
```

**Conditional inference tree**
```{r}
# For the Inference Tree to work, we must have all variables as numeric data

Ctree <- ctree(formula, data = train, control = ctree_control(testtype = "Bonferroni")) #I think that this already include the Control for inference trees, there is a possibility to do it with CV and caret, but it did not work out yet
Ctree

plot(Ctree, type = "simple",gp = gpar(fontsize = 6),
  inner_panel=node_inner,
  ip_args=list(id = FALSE), main = "Conditional Inference Tree for Austria 2019") #Überschrift größe ändern

```
Instead of the default tuning function we use the caret package for cross validation
```{r}
### data = in data 2019 geändert von train!
caret_ctree <- train(formula, data = data19, method = "ctree", trControl = fitControl, na.action = na.pass)
caret_ctree


caret_ctree_B <- ctree(formula, data = data19, control = ctree_control(testtype = "Bonferroni", mincriterion = 0.99)) 
caret_ctree_B

plot(caret_ctree_B,gp = gpar(fontsize = 6),
  inner_panel=node_inner,
  ip_args=list(abbreviate = FALSE,id = FALSE), main = "Opportunity Conditional Inference Tree for Austria 2019 - Cross Validated")
```

```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
# Das ist der gleiche Baum wie oben, nur mit anderem Package erstellt. Sieht aber scheiße aus
plot(caret_ctree,gp = gpar(fontsize = 6),
  inner_panel=node_inner,
  ip_args=list(id = FALSE))

plot(caret_ctree$finalModel, type = "simple")
```
*Graphic representation of the tuning parameters*
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
plot(caret_ctree) # RMSE vs p-value our resampling parameter
plot(caret_rpart)
# plotcp(tree_1)
```

*Predictions*
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
test$P_AtCt <- predict(Ctree, newdata = as.data.frame(test))
test$perror <- (test$P_AtCt - test$inc_net_log)^2
test$RMSE <- sqrt(sum((test$P_AtCt - test$inc_net_log)^2/nrow(test), na.rm = T))
head(test$RMSE)

plot(test$P_AtCt, test$inc_net_log) #ADD GGPLOT und machs schön!

test$P_AtCt_caret <- predict(caret_rpart, newdata = as.data.frame(test))
test$perror_caret <- (test$P_AtCt_caret - test$inc_net_log)^2
test$RMSE_caret <- sqrt(sum((test$P_AtCt_caret - test$inc_net_log)^2/nrow(test), na.rm = T))
head(test$RMSE_caret)
```
*Random Forest*
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}
cf <- cforest(formula, data19, na.action = na.pass, control = ctree_control(teststat = "quadratic", testtype = "Bonferroni", mincriterion = 0.99), ytrafo = NULL, scores = NULL, ntree = 500L, perturb = list(replace = FALSE, fraction = 0.8))

hat_cf <- predict(cf, newdata = test, OOB = TRUE, type = "response")

# Calculate the RMSE by hand for cforest and boosted ctree to compare 

varimp(cf, mincriterion = 0, OOB = TRUE) 
importance_cf <- data.frame(varimp(cf, mincriterion = 0, OOB = TRUE))
names(importance_cf) <- "importance"
importance_cf$var_name = rownames(importance_cf)
importance_cf <- importance_cf  %>% arrange( desc(importance))
```

```{r}
ggplot(importance_cf, aes(x = var_name, y = importance)) +
    geom_point() +
    scale_x_discrete(limits = importance_cf$var_name[order(importance_cf$importance)]) +
    labs(title = "Conditional Forest variable importance - Austria 2019", x = "", y = "Mean decrease in sum of squared residuals") +
    coord_flip() +
    theme(axis.text.y = element_text(hjust = 0))
```
We find that the variable sex, is the single most important variable in determining ones income in Austria. However, sex is not a generationally transmittable circumstance and, while it is a circumstance it is not exactly what we were trying to answer with our exercise. Therefore, we exclude it in the next step and create a new conditional inference forest.
```{r}

```

*Boosted Inference Tree*
```{r echo=T, message=FALSE, error=FALSE, warning=FALSE}

# cf_boosted <- blackboost(formula, data = data19, na.action = na.pass, control = boost_control(), tree_controls = partykit::ctree_control())
# cf_boosted
# 
 cf_boosted_2 <- train(formula, data19, method = "ctree2", trControl = fitControl, tuneGrid = NULL, na.action = na.pass)
 cf_boosted_2
 plot(cf_boosted_2$finalModel, type = "simple")

# Calc RMSE!!

```
Variable Importance Boosted Inference Tree
```{r}





```
